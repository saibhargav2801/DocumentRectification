{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7a146c19",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import shutil\n",
    "import numpy as np\n",
    "import skimage\n",
    "from skimage import io\n",
    "import argparse\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "046f0365",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "92f28fce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a09eb671",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6cdf55d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "9d11a253",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgPath = 'Wrap.jpg'\n",
    "modelPath = 'model_geoNet.pkl'\n",
    "saveImgPath = 'result.jpg'\n",
    "saveFlowPath = 'IMG_WRAP.npy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b3e4bf03",
   "metadata": {},
   "outputs": [],
   "source": [
    "class plainEncoderBlock(nn.Module):\n",
    "    def __init__(self, inChannel, outChannel, stride):\n",
    "    \n",
    "        super(plainEncoderBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(inChannel, outChannel, kernel_size=3, stride=stride, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(outChannel)\n",
    "        self.conv2 = nn.Conv2d(outChannel, outChannel, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(outChannel)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.bn1(self.conv1(x)))\n",
    "        x = F.relu(self.bn2(self.conv2(x)))\n",
    "        return x\n",
    "    \n",
    "class plainDecoderBlock(nn.Module):\n",
    "    def __init__(self, inChannel, outChannel, stride):\n",
    "    \n",
    "        super(plainDecoderBlock, self).__init__()\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(inChannel, inChannel, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(inChannel)\n",
    "        \n",
    "        self.conv2 = nn.Conv2d(inChannel, outChannel, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(outChannel)\n",
    "        \n",
    "        self.up = None\n",
    "        \n",
    "        if stride != 1:\n",
    "            self.up = nn.Upsample(scale_factor=2, mode='bilinear')\n",
    "            #self.up = nn.Upsample(scale_factor=2, mode='nearest')\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.bn1(self.conv1(x)))\n",
    "        x = F.relu(self.bn2(self.conv2(x)))\n",
    "        \n",
    "        if self.up is not None:\n",
    "            x = self.up(x)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "\n",
    "class resEncoderBlock(nn.Module):\n",
    "    def __init__(self, inChannel, outChannel, stride):\n",
    "    \n",
    "        super(resEncoderBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(inChannel, outChannel, kernel_size=3, stride=stride, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(outChannel)\n",
    "        self.conv2 = nn.Conv2d(outChannel, outChannel, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(outChannel)\n",
    "        \n",
    "        self.downsample = None\n",
    "        if stride != 1:  \n",
    "            self.downsample = nn.Sequential(\n",
    "                nn.Conv2d(inChannel, outChannel, kernel_size=1, stride=stride),\n",
    "                nn.BatchNorm2d(outChannel))\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "        \n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.bn2(self.conv2(out))\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            residual = self.downsample(x)\n",
    "        \n",
    "        out += residual\n",
    "        out = F.relu(out)\n",
    "        return out\n",
    "    \n",
    "class resDecoderBlock(nn.Module):\n",
    "    def __init__(self, inChannel, outChannel, stride):\n",
    "    \n",
    "        super(resDecoderBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(inChannel, inChannel, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(inChannel)\n",
    "        \n",
    "        self.downsample = None\n",
    "        self.up = None\n",
    "        \n",
    "        if stride == 1:\n",
    "            self.conv2 = nn.Conv2d(inChannel, outChannel, kernel_size=3, stride=1, padding=1)\n",
    "            self.bn2 = nn.BatchNorm2d(outChannel)\n",
    "        else:\n",
    "            self.conv2 = nn.Conv2d(inChannel, outChannel, kernel_size=3, stride=1, padding=1)\n",
    "            self.bn2 = nn.BatchNorm2d(outChannel)\n",
    "            self.up = nn.Upsample(scale_factor=2, mode='bilinear')\n",
    "            #self.up = nn.Upsample(scale_factor=2, mode='nearest')\n",
    "            \n",
    "            self.downsample = nn.Sequential(\n",
    "                nn.Conv2d(inChannel, outChannel, kernel_size=1, stride=1),\n",
    "                nn.BatchNorm2d(outChannel),\n",
    "                nn.Upsample(scale_factor=2, mode='bilinear'))\n",
    "                #nn.Upsample(scale_factor=2, mode='nearest'))   \n",
    "        \n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "        \n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        \n",
    "        if self.up is not None:\n",
    "            out = self.up(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            residual = self.downsample(x)\n",
    "        \n",
    "        out += residual\n",
    "        out = F.relu(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dc939aaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GeoNet(nn.Module):\n",
    "    def __init__(self, layers):\n",
    "        super(GeoNet, self).__init__()  \n",
    "        \n",
    "        self.conv = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn = nn.BatchNorm2d(64)\n",
    "        \n",
    "        self.en_layer1 = self.make_encoder_layer(plainEncoderBlock, 64, 64, layers[0], stride=1)  \n",
    "        self.en_layer2 = self.make_encoder_layer(resEncoderBlock, 64, 128, layers[1], stride=2)\n",
    "        self.en_layer3 = self.make_encoder_layer(resEncoderBlock, 128, 256, layers[2], stride=2)\n",
    "        self.en_layer4 = self.make_encoder_layer(resEncoderBlock, 256, 512, layers[3], stride=2)\n",
    "        self.en_layer5 = self.make_encoder_layer(resEncoderBlock, 512, 512, layers[4], stride=2)\n",
    "        \n",
    "        self.de_layer5 = self.make_decoder_layer(resDecoderBlock, 512, 512, layers[4], stride=2)\n",
    "        self.de_layer4 = self.make_decoder_layer(resDecoderBlock, 512, 256, layers[3], stride=2)\n",
    "        self.de_layer3 = self.make_decoder_layer(resDecoderBlock, 256, 128, layers[2], stride=2)\n",
    "        self.de_layer2 = self.make_decoder_layer(resDecoderBlock, 128, 64, layers[1], stride=2)\n",
    "        self.de_layer1 = self.make_decoder_layer(plainDecoderBlock, 64, 64, layers[0], stride=1)\n",
    "        \n",
    "        self.conv_end = nn.Conv2d(64, 2, kernel_size=3, stride=1, padding=1)\n",
    "        \n",
    "        self.fconv = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.fbn = nn.BatchNorm2d(64)\n",
    "        self.f_en_layer1 = self.make_encoder_layer(plainEncoderBlock, 64, 64, layers[0], stride=1)  \n",
    "        self.f_en_layer2 = self.make_encoder_layer(resEncoderBlock, 64, 128, layers[1], stride=2)\n",
    "        self.f_en_layer3 = self.make_encoder_layer(resEncoderBlock, 128, 256, layers[2], stride=2)\n",
    "        self.f_en_layer4 = self.make_encoder_layer(resEncoderBlock, 256, 512, layers[3], stride=2)\n",
    "        self.f_en_layer5 = self.make_encoder_layer(resEncoderBlock, 512, 512, layers[4], stride=2)\n",
    "        \n",
    "        self.f_en_layer6 = self.make_encoder_layer(resEncoderBlock, 512, 512, 1, stride=2)\n",
    "        self.f_en_layer7 = self.make_encoder_layer(resEncoderBlock, 512, 512, 1, stride=2)\n",
    "        self.f_en_layer8 = self.make_encoder_layer(resEncoderBlock, 512, 512, 1, stride=2)\n",
    "        \n",
    "        self.fc1 = nn.Linear(512 * 2 * 2, 1024)\n",
    "        self.fc1bn = nn.BatchNorm1d(1024)\n",
    "        self.fc2 = nn.Linear(1024, 512)\n",
    "        self.fc2bn = nn.BatchNorm1d(512)\n",
    "        \n",
    "        self.catconv = nn.Conv2d(1024, 512, kernel_size=1, bias=False)\n",
    "        self.catbn  = nn.BatchNorm2d(512)\n",
    "        \n",
    "                       \n",
    "        # weight initializaion with Kaiming method\n",
    "        \n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
    "                m.weight.data.normal_(0, math.sqrt(2. / n))\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                m.weight.data.fill_(1)\n",
    "                m.bias.data.zero_()\n",
    "        \n",
    "        \n",
    "    def make_encoder_layer(self, block, inChannel, outChannel, block_num, stride):\n",
    "\n",
    "        layers = []\n",
    "        layers.append(block(inChannel, outChannel, stride=stride))\n",
    "        for i in range(1, block_num):\n",
    "            layers.append(block(outChannel, outChannel, stride=1))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "    \n",
    "    def make_decoder_layer(self, block, inChannel, outChannel, block_num, stride):\n",
    "\n",
    "        layers = []\n",
    "        for i in range(0, block_num-1):\n",
    "            layers.append(block(inChannel, inChannel, stride=1))\n",
    "            \n",
    "        layers.append(block(inChannel, outChannel, stride=stride))\n",
    "        \n",
    "        return nn.Sequential(*layers)\n",
    "                       \n",
    "    def forward(self, x, y):\n",
    "        \n",
    "        x = F.relu(self.bn(self.conv(x)))\n",
    "        x = self.en_layer1(x)     #256\n",
    "        x = self.en_layer2(x)     #128\n",
    "        x = self.en_layer3(x)     #64\n",
    "        x = self.en_layer4(x)     #32\n",
    "        x = self.en_layer5(x)     #16\n",
    "        \n",
    "        y = F.relu(self.fbn(self.fconv(y)))\n",
    "        y = self.f_en_layer1(y)     #256\n",
    "        y = self.f_en_layer2(y)     #128\n",
    "        y = self.f_en_layer3(y)     #64\n",
    "        y = self.f_en_layer4(y)     #32\n",
    "        y = self.f_en_layer5(y)     #16\n",
    "        \n",
    "        y = self.f_en_layer6(y)     #8\n",
    "        y = self.f_en_layer7(y)     #4\n",
    "        y = self.f_en_layer8(y)     #2\n",
    "        \n",
    "        y = y.view(-1, 512*2*2)\n",
    "        \n",
    "        y = F.relu(self.fc1bn(self.fc1(y)))\n",
    "        y = F.relu(self.fc2bn(self.fc2(y)))\n",
    "        y = y.unsqueeze(2).unsqueeze(2).expand_as(x)\n",
    "        \n",
    "        x = torch.cat([x, y], dim=1)\n",
    "        \n",
    "        x = F.relu(self.catbn(self.catconv(x)))\n",
    "        \n",
    "        x = self.de_layer5(x)     \n",
    "        x = self.de_layer4(x)     \n",
    "        x = self.de_layer3(x)     \n",
    "        x = self.de_layer2(x)     \n",
    "        x = self.de_layer1(x)        \n",
    "        \n",
    "        x = self.conv_end(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbbec370",
   "metadata": {},
   "source": [
    "### Resizing the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "6bf99a31",
   "metadata": {},
   "outputs": [],
   "source": [
    "H = 2000\n",
    "W = 1500\n",
    "img = io.imread(imgPath)\n",
    "h, w = img.shape[0:2]\n",
    "    \n",
    "if h > w:\n",
    "    ratio = float(h)/float(w)\n",
    "\n",
    "    if (ratio > float(H)/float(W)):\n",
    "        img = skimage.transform.resize(img, (int(ratio*W), W), order=1)\n",
    "    else:\n",
    "        img = skimage.transform.resize(img, (H, int(H/ratio)), order=1)\n",
    "\n",
    "    yc = int(img.shape[0]/2)\n",
    "    xc = int(img.shape[1]/2)\n",
    "    img = img[yc - int(H/2):yc + int(H/2), xc - int(W/2):xc + int(W/2)]\n",
    "        \n",
    "else:\n",
    "    ratio = float(w)/float(h)\n",
    "        \n",
    "    if (ratio > float(H)/float(W)):\n",
    "        img = skimage.transform.resize(img, (W, int(W*ratio)), order=1)\n",
    "    else:\n",
    "        img = skimage.transform.resize(img, (int(H/ratio), H), order=1)\n",
    "         \n",
    "    yc = int(img.shape[0]/2)\n",
    "    xc = int(img.shape[1]/2)\n",
    "    img = img[yc - int(W/2):yc + int(W/2), xc - int(H/2):xc + int(H/2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "8d3398dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 1500, 3)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d240b95",
   "metadata": {},
   "source": [
    "### Image Padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "70d4c3d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def padImg(img):\n",
    "    '''\n",
    "    pad image twice.\n",
    "    The first padding is to make sure the patches cover all image regions.\n",
    "    The second padding is used for cropping the global patch.\n",
    "    '''\n",
    "    \n",
    "    H = img.shape[0]\n",
    "    W = img.shape[1]\n",
    "    \n",
    "    globalFct = 4\n",
    "    patchRes = 256\n",
    "    ovlp = int(patchRes * 0.25)\n",
    "    \n",
    "    padH = (int((H - patchRes)/(patchRes - ovlp) + 1) * (patchRes - ovlp) + patchRes) - H\n",
    "    padW = (int((W - patchRes)/(patchRes - ovlp) + 1) * (patchRes - ovlp) + patchRes) - W\n",
    "    \n",
    "    padding = int(patchRes * (globalFct - 1) / 2.0)\n",
    "\n",
    "    padImg = cv2.copyMakeBorder(img, 0, padH, 0, padW, cv2.BORDER_REPLICATE)\n",
    "    padImg = cv2.copyMakeBorder(padImg, padding, padding, padding, padding, cv2.BORDER_REPLICATE)\n",
    "    \n",
    "    return padImg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b97f3bdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cropToPatch(img):\n",
    "    '''\n",
    "    crop the image to local and global patches\n",
    "    '''\n",
    "\n",
    "    H = img.shape[0]\n",
    "    W = img.shape[1]\n",
    "    \n",
    "    globalFct = 4\n",
    "    patchRes = 256\n",
    "    ovlp = int(patchRes * 0.25)\n",
    "    padding = int(patchRes * (globalFct - 1) / 2.0)\n",
    "\n",
    "    cropH = patchRes\n",
    "    cropW = patchRes\n",
    "\n",
    "    ynum = int((H - (globalFct - 1) * cropH - cropH)/(cropH - ovlp)) + 1\n",
    "    xnum = int((W - (globalFct - 1) * cropW - cropW)/(cropW - ovlp)) + 1\n",
    "    \n",
    "    totalLocal = np.zeros((ynum, xnum, patchRes, patchRes, 3), dtype=np.uint8)\n",
    "    totalGloba = np.zeros((ynum, xnum, 256, 256, 3), dtype=np.uint8)\n",
    "\n",
    "    for j in range(0, ynum):\n",
    "        for i in range(0, xnum):\n",
    "\n",
    "            x = int(padding + i * (cropW - ovlp))\n",
    "            y = int(padding + j * (cropH - ovlp))\n",
    "\n",
    "            totalLocal[j, i] = img[y:int(y + patchRes), x:int(x + patchRes)]\n",
    "\n",
    "            gx = int(x - padding)\n",
    "            gy = int(y - padding)\n",
    "            globalpatch = img[gy:int(gy + globalFct * patchRes), gx:int(gx + globalFct * patchRes)]\n",
    "            globalpatch = skimage.transform.resize(globalpatch, (256, 256)) * 255.0\n",
    "            totalGloba[j, i] = globalpatch\n",
    "            \n",
    "    return totalLocal, totalGloba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "759cbbef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n"
     ]
    }
   ],
   "source": [
    "io.imsave(saveImgPath, img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "ea4df97c",
   "metadata": {},
   "outputs": [],
   "source": [
    "totalLocalPatch, totalGlobaPatch = cropToPatch(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a969cd77",
   "metadata": {},
   "outputs": [],
   "source": [
    "def testRealFlow(modelPath, localPatch, globalPatch):\n",
    "    '''\n",
    "    estimate the flows\n",
    "    '''\n",
    "\n",
    "    transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "    model = GeoNet([1, 1, 1, 1, 1])\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "        model = model.cuda()\n",
    "        \n",
    "    if torch.cuda.device_count() > 1:\n",
    "        model = nn.DataParallel(model)\n",
    "        model.load_state_dict(torch.load(modelPath),strict=False)\n",
    "    else:\n",
    "        state_dict = torch.load(modelPath)\n",
    "        new_state_dict = OrderedDict()\n",
    "        for k, v in state_dict.items():\n",
    "            name = k[7:]\n",
    "            new_state_dict[name] = v\n",
    "        model.load_state_dict(new_state_dict)  \n",
    "        \n",
    "    model.eval()\n",
    "    \n",
    "    ynum = localPatch.shape[0]\n",
    "    xnum = localPatch.shape[1]\n",
    "    scal = localPatch.shape[2]\n",
    "    \n",
    "    totalFlow = np.zeros((ynum, xnum, 2, scal, scal), dtype = np.float32)\n",
    "    \n",
    "    for j in range(0, ynum):\n",
    "        for i in range(0, xnum):\n",
    "\n",
    "            temp_localPatch = localPatch[j, i]\n",
    "            temp_globaPatch = globalPatch[j, i]\n",
    "        \n",
    "            temp_localPatch = transform(temp_localPatch)\n",
    "            temp_globaPatch = transform(temp_globaPatch)\n",
    "\n",
    "            if torch.cuda.is_available():\n",
    "                temp_localPatch = temp_localPatch.cuda()\n",
    "                temp_globaPatch = temp_globaPatch.cuda()\n",
    "\n",
    "            temp_localPatch = temp_localPatch.view(1,3,scal,scal)\n",
    "            temp_globaPatch = temp_globaPatch.view(1,3,256,256)\n",
    "            \n",
    "            temp_localPatch = Variable(temp_localPatch)\n",
    "            temp_globaPatch = Variable(temp_globaPatch)\n",
    "            \n",
    "            flow_output = model(temp_localPatch, temp_globaPatch)\n",
    "\n",
    "            u = flow_output.data.cpu().numpy()[0][0]\n",
    "            v = flow_output.data.cpu().numpy()[0][1]\n",
    "            \n",
    "            totalFlow[j,i,0] = u\n",
    "            totalFlow[j,i,1] = v\n",
    "\n",
    "    return totalFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "93769677",
   "metadata": {},
   "outputs": [],
   "source": [
    "totalFlow = testRealFlow(modelPath, totalLocalPatch, totalGlobaPatch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "3dff8962",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(saveFlowPath, totalFlow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "07e813e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# python eval.py [--imgPath [PATH]] [--modelPath [PATH]]\n",
    "#                [--saveImgPath [PATH]] [--saveFlowPath [PATH]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "cc296806",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6, 3, 2, 256, 256)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "totalFlow.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "c68440f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 256, 256)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "totalFlow[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "21ea253a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import skimage.io as io\n",
    "from numba import cuda\n",
    "import math\n",
    "import argparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "98936fa3",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not broadcast input array from shape (3,2,256,256) into shape (1024,768)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [40]\u001b[0m, in \u001b[0;36m<cell line: 195>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    193\u001b[0m distortedImg \u001b[38;5;241m=\u001b[39m io\u001b[38;5;241m.\u001b[39mimread(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mWrap.jpg\u001b[39m\u001b[38;5;124m'\u001b[39m)  \n\u001b[0;32m    194\u001b[0m flow \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mload(flow_path)\n\u001b[1;32m--> 195\u001b[0m resImg, resMsk \u001b[38;5;241m=\u001b[39m \u001b[43mrectification\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdistortedImg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflow\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    196\u001b[0m io\u001b[38;5;241m.\u001b[39mimsave(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mresult.png\u001b[39m\u001b[38;5;124m'\u001b[39m, resImg)\n",
      "Input \u001b[1;32mIn [40]\u001b[0m, in \u001b[0;36mrectification\u001b[1;34m(distorted, flow)\u001b[0m\n\u001b[0;32m    158\u001b[0m paddistorted[H, W] \u001b[38;5;241m=\u001b[39m distorted[H\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, W\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m    160\u001b[0m padu \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(np\u001b[38;5;241m.\u001b[39mzeros((H \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m, W \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m)), dtype \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mfloat32)\n\u001b[1;32m--> 161\u001b[0m padu[\u001b[38;5;241m0\u001b[39m:H, \u001b[38;5;241m0\u001b[39m:W] \u001b[38;5;241m=\u001b[39m flow[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m:H, \u001b[38;5;241m0\u001b[39m:W]\n\u001b[0;32m    162\u001b[0m padu[H, \u001b[38;5;241m0\u001b[39m:W] \u001b[38;5;241m=\u001b[39m flow[\u001b[38;5;241m0\u001b[39m][H\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m:W]\n\u001b[0;32m    163\u001b[0m padu[\u001b[38;5;241m0\u001b[39m:H, W] \u001b[38;5;241m=\u001b[39m flow[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m:H, W\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n",
      "\u001b[1;31mValueError\u001b[0m: could not broadcast input array from shape (3,2,256,256) into shape (1024,768)"
     ]
    }
   ],
   "source": [
    "img_path = 'Wrap.jpg'\n",
    "flow_path = 'IMG_WRAP.npy'\n",
    "\n",
    "@cuda.jit(device=True)\n",
    "def iterSearchShader(padu, padv, xr, yr, maxIter, precision):\n",
    "    \n",
    "    H = padu.shape[0] - 1\n",
    "    W = padu.shape[1] - 1\n",
    "    \n",
    "    if abs(padu[yr,xr]) < precision and abs(padv[yr,xr]) < precision:\n",
    "        return xr, yr\n",
    "\n",
    "    else:\n",
    "        # Our initialize method in this paper, can see the overleaf for detail\n",
    "        if (xr + 1) <= (W - 1):\n",
    "            dif = padu[yr,xr + 1] - padu[yr,xr]\n",
    "            u_next = padu[yr,xr]/(1 + dif)\n",
    "        else:\n",
    "            dif = padu[yr,xr] - padu[yr,xr - 1]\n",
    "            u_next = padu[yr,xr]/(1 + dif)\n",
    "\n",
    "        if (yr + 1) <= (H - 1):\n",
    "            dif = padv[yr + 1,xr] - padv[yr,xr]\n",
    "            v_next = padv[yr,xr]/(1 + dif)\n",
    "        else:\n",
    "            dif = padv[yr,xr] - padv[yr - 1,xr]\n",
    "            v_next = padv[yr,xr]/(1 + dif)\n",
    "\n",
    "        i = xr - u_next\n",
    "        j = yr - v_next\n",
    "        '''\n",
    "        i = xr - padu[yr,xr]\n",
    "        j = yr - padv[yr,xr]\n",
    "        '''\n",
    "        # The same as traditinal iterative search method\n",
    "        for iter in range(maxIter):\n",
    "\n",
    "            if 0<= i <= (W - 1) and 0 <= j <= (H - 1):\n",
    "\n",
    "                u11 = padu[int(j), int(i)]\n",
    "                v11 = padv[int(j), int(i)]\n",
    "\n",
    "                u12 = padu[int(j), int(i) + 1]\n",
    "                v12 = padv[int(j), int(i) + 1]\n",
    "\n",
    "                u21 = padu[int(j) + 1, int(i)]\n",
    "                v21 = padv[int(j) + 1, int(i)]\n",
    "\n",
    "                u22 = padu[int(j) + 1, int(i) + 1]\n",
    "                v22 = padv[int(j) + 1, int(i) + 1]\n",
    "\n",
    "\n",
    "                u = u11*(int(i) + 1 - i)*(int(j) + 1 - j) + u12*(i - int(i))*(int(j) + 1 - j) + \\\n",
    "                    u21*(int(i) + 1 - i)*(j - int(j)) + u22*(i - int(i))*(j - int(j))\n",
    "\n",
    "                v = v11*(int(i) + 1 - i)*(int(j) + 1 - j) + v12*(i - int(i))*(int(j) + 1 - j) + \\\n",
    "                    v21*(int(i) + 1 - i)*(j - int(j)) + v22*(i - int(i))*(j - int(j))\n",
    "\n",
    "                i_next = xr - u\n",
    "                j_next = yr - v                \n",
    "\n",
    "                if abs(i - i_next)<precision and abs(j - j_next)<precision:\n",
    "                    return i, j\n",
    "\n",
    "                i = i_next\n",
    "                j = j_next\n",
    "\n",
    "            else:     \n",
    "                return -1, -1\n",
    "        '''\n",
    "        return -1, -1\n",
    "        '''\n",
    "        # if the search doesn't converge within max iter, it will return the last iter result\n",
    "        if 0 <= i_next <= (W - 1) and 0 <= j_next <= (H - 1):\n",
    "            return i_next, j_next\n",
    "        elif 0 <= i <= (W - 1) and 0 <= j <= (H - 1):\n",
    "            return i, j\n",
    "        else:\n",
    "            return -1, -1\n",
    "        \n",
    "\n",
    "            \n",
    "@cuda.jit(device=True)\n",
    "def biInterpolation(distorted, i, j):\n",
    "    Q11 = distorted[int(j), int(i)]\n",
    "    Q12 = distorted[int(j), int(i) + 1]\n",
    "    Q21 = distorted[int(j) + 1, int(i)]\n",
    "    Q22 = distorted[int(j) + 1, int(i) + 1]\n",
    "    pixel = Q11*(int(i) + 1 - i)*(int(j) + 1 - j) + Q12*(i - int(i))*(int(j) + 1 - j) + \\\n",
    "            Q21*(int(i) + 1 - i)*(j - int(j)) + Q22*(i - int(i))*(j - int(j))\n",
    "    return pixel\n",
    "\n",
    "\n",
    "@cuda.jit\n",
    "def iterSearch(padu, padv, paddistorted, resultImg, maxIter, precision, resultMsk):\n",
    "    \n",
    "    H = padu.shape[0] - 1\n",
    "    W = padu.shape[1] - 1\n",
    "    \n",
    "    start_x, start_y = cuda.grid(2)\n",
    "    stride_x, stride_y = cuda.gridsize(2)\n",
    "    \n",
    "    for xr in range(start_x, W, stride_x):\n",
    "        for yr in range(start_y, H, stride_y):\n",
    "\n",
    "            i,j = iterSearchShader(padu, padv, xr, yr, maxIter, precision)\n",
    "\n",
    "            if(i != -1) and (j != -1):\n",
    "                resultImg[yr, xr,0] = biInterpolation(paddistorted[:,:,0], i, j)\n",
    "                resultImg[yr, xr,1] = biInterpolation(paddistorted[:,:,1], i, j)\n",
    "                resultImg[yr, xr,2] = biInterpolation(paddistorted[:,:,2], i, j)\n",
    "            else:\n",
    "                resultMsk[yr, xr] = 255\n",
    "\n",
    "@cuda.jit\n",
    "def iterSearchGrey(padu, padv, paddistorted, resultImg, maxIter, precision, resultMsk):\n",
    "    \n",
    "    H = padu.shape[0] - 1\n",
    "    W = padu.shape[1] - 1\n",
    "  \n",
    "    start_x, start_y = cuda.grid(2)\n",
    "    stride_x, stride_y = cuda.gridsize(2)\n",
    "    \n",
    "    for xr in range(start_x, W, stride_x):\n",
    "        for yr in range(start_y, H, stride_y):\n",
    "\n",
    "            i,j = iterSearchShader(padu, padv, xr, yr, maxIter, precision)\n",
    "\n",
    "            if(i != -1) and (j != -1):\n",
    "                resultImg[yr, xr] = biInterpolation(paddistorted[:,:], i, j)\n",
    "            else:\n",
    "                resultMsk[yr, xr] = 255\n",
    "\n",
    "def rectification(distorted, flow):\n",
    "    \n",
    "    H = distorted.shape[0]\n",
    "    W = distorted.shape[1]\n",
    "\n",
    "    maxIter = 100\n",
    "    precision = 1e-2\n",
    "\n",
    "    isGrey = True\n",
    "    resultMsk = np.array(np.zeros((H, W)), dtype = np.uint8)\n",
    "    if len(distorted.shape) == 3:\n",
    "        resultImg = np.array(np.zeros((H, W, 3)), dtype = np.uint8)\n",
    "        paddistorted = np.array(np.zeros((H + 1, W + 1, 3)), dtype = np.uint8)\n",
    "        resultImg.fill(255)\n",
    "        isGrey = False\n",
    "    else:\n",
    "        resultImg = np.array(np.zeros((H, W)), dtype = np.uint8)\n",
    "        paddistorted = np.array(np.zeros((H + 1, W + 1)), dtype = np.uint8)\n",
    "        resultImg.fill(255)\n",
    "        isGrey = True\n",
    "\n",
    "    paddistorted[0:H, 0:W] = distorted[0:H, 0:W]\n",
    "    paddistorted[H, 0:W] = distorted[H-1, 0:W]\n",
    "    paddistorted[0:H, W] = distorted[0:H, W-1]\n",
    "    paddistorted[H, W] = distorted[H-1, W-1]\n",
    "\n",
    "    padu = np.array(np.zeros((H + 1, W + 1)), dtype = np.float32)\n",
    "    padu[0:H, 0:W] = flow[0][0:H, 0:W]\n",
    "    padu[H, 0:W] = flow[0][H-1, 0:W]\n",
    "    padu[0:H, W] = flow[0][0:H, W-1]\n",
    "    padu[H, W] = flow[0][H-1, W-1]\n",
    "\n",
    "    padv = np.array(np.zeros((H + 1, W + 1)), dtype = np.float32)\n",
    "    padv[0:H, 0:W] = flow[1][0:H, 0:W]\n",
    "    padv[H, 0:W] = flow[1][H-1, 0:W]\n",
    "    padv[0:H, W] = flow[1][0:H, W-1]\n",
    "    padv[H, W] = flow[1][H-1, W-1]\n",
    "\n",
    "    padu = cuda.to_device(padu)\n",
    "    padv = cuda.to_device(padv)\n",
    "    paddistorted = cuda.to_device(paddistorted)\n",
    "    resultImg = cuda.to_device(resultImg)\n",
    "    resultMsk = cuda.to_device(resultMsk)\n",
    "\n",
    "    threadsperblock = (16, 16)\n",
    "    blockspergrid_x = math.ceil(W / threadsperblock[0])\n",
    "    blockspergrid_y = math.ceil(H / threadsperblock[1])\n",
    "    blockspergrid = (blockspergrid_x, blockspergrid_y)\n",
    "\n",
    "    if isGrey:\n",
    "        iterSearchGrey[blockspergrid, threadsperblock](padu, padv, paddistorted, resultImg, maxIter, precision, resultMsk)\n",
    "    else:\n",
    "        iterSearch[blockspergrid, threadsperblock](padu, padv, paddistorted, resultImg, maxIter, precision, resultMsk)\n",
    "\n",
    "    resultImg = resultImg.copy_to_host()\n",
    "    resultMsk = resultMsk.copy_to_host()\n",
    "    \n",
    "    return resultImg, resultMsk\n",
    "    \n",
    "distortedImg = io.imread('Wrap.jpg')  \n",
    "flow = np.load(flow_path)\n",
    "resImg, resMsk = rectification(distortedImg, flow)\n",
    "io.imsave('result.png', resImg) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "31665f9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "distorted = io.imread('result.jpg')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "3a5d82e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "H = distorted.shape[0]\n",
    "W = distorted.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "fb21fc3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2000"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "H"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "2c341e87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1500"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "7488fe93",
   "metadata": {},
   "outputs": [],
   "source": [
    "    maxIter = 100\n",
    "    precision = 1e-2\n",
    "\n",
    "    isGrey = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "a62a99c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(distorted.shape) == 3:\n",
    "        resultImg = np.array(np.zeros((H, W, 3)), dtype = np.uint8)\n",
    "        paddistorted = np.array(np.zeros((H + 1, W + 1, 3)), dtype = np.uint8)\n",
    "        resultImg.fill(255)\n",
    "        isGrey = False\n",
    "else:\n",
    "    resultImg = np.array(np.zeros((H, W)), dtype = np.uint8)\n",
    "    paddistorted = np.array(np.zeros((H + 1, W + 1)), dtype = np.uint8)\n",
    "    resultImg.fill(255)\n",
    "    isGrey = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "4f3b7158",
   "metadata": {},
   "outputs": [],
   "source": [
    "paddistorted[0:H, 0:W] = distorted[0:H, 0:W]\n",
    "paddistorted[H, 0:W] = distorted[H-1, 0:W]\n",
    "paddistorted[0:H, W] = distorted[0:H, W-1]\n",
    "paddistorted[H, W] = distorted[H-1, W-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "34e7589c",
   "metadata": {},
   "outputs": [],
   "source": [
    "flow = np.load(flow_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "46973f8d",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not broadcast input array from shape (3,2,256,256) into shape (2000,1500)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [64]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m padu \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(np\u001b[38;5;241m.\u001b[39mzeros((H \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m, W \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m)), dtype \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mfloat32)\n\u001b[1;32m----> 2\u001b[0m padu[\u001b[38;5;241m0\u001b[39m:H, \u001b[38;5;241m0\u001b[39m:W] \u001b[38;5;241m=\u001b[39m flow[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m:H, \u001b[38;5;241m0\u001b[39m:W]\n\u001b[0;32m      3\u001b[0m padu[H, \u001b[38;5;241m0\u001b[39m:W] \u001b[38;5;241m=\u001b[39m flow[\u001b[38;5;241m0\u001b[39m][H\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m:W]\n\u001b[0;32m      4\u001b[0m padu[\u001b[38;5;241m0\u001b[39m:H, W] \u001b[38;5;241m=\u001b[39m flow[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m:H, W\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n",
      "\u001b[1;31mValueError\u001b[0m: could not broadcast input array from shape (3,2,256,256) into shape (2000,1500)"
     ]
    }
   ],
   "source": [
    "padu = np.array(np.zeros((H + 1, W + 1)), dtype = np.float32)\n",
    "padu[0:H, 0:W] = flow[0][0:H, 0:W]\n",
    "padu[H, 0:W] = flow[0][H-1, 0:W]\n",
    "padu[0:H, W] = flow[0][0:H, W-1]\n",
    "padu[H, W] = flow[0][H-1, W-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "7eaff80a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 1500)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padu[:H,:W].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "fb737220",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 2, 256, 256)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flow[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "825e84d0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
